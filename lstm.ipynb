{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "import bz2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6000                 \n",
    "max_length = 500                  \n",
    "train_set_proportion = 0.9        \n",
    "num_data_points = 10000           \n",
    "embedding_size = 128             \n",
    "train_size = int(num_data_points * train_set_proportion)\n",
    "batch_size = 1024\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reTokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def labelsandtexts(file):\n",
    "  labels=[]\n",
    "  reviews=[]\n",
    "  for li in bz2.BZ2File(file):\n",
    "    x=li.decode(\"utf-8\")\n",
    "    labels.append(int(x[9])-1)\n",
    "    reviews.append(x[10:].strip())\n",
    "  return np.array(labels), reviews\n",
    "labels, reviews= labelsandtexts('train.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in range(len(reviews)):\n",
    "    tokens = reTokenizer.tokenize(reviews[i])\n",
    "    reviews[i] = []\n",
    "    for word in tokens:\n",
    "        word = word.lower()\n",
    "        all_words.append(word)\n",
    "        reviews[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = FreqDist(all_words)\n",
    "all_words = all_words.most_common(vocab_size)\n",
    "\n",
    "word2int = {all_words[i][0]: i+1 for i in range(vocab_size)}\n",
    "int2word = {x: y for y, x in word2int.items()}\n",
    "dict_as_list = list(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review2intlist(rev_text):\n",
    "    int_list = []\n",
    "    for word in rev_text:\n",
    "        if word in word2int.keys():\n",
    "            int_list.append(word2int[word])\n",
    "    return int_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in reviews:\n",
    "    X.append(np.asarray(review2intlist(i), dtype=int))\n",
    "X = sequence.pad_sequences(X, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_inputs = np.zeros(shape=(max_length, num_data_points), dtype=np.float32)\n",
    "for i in range(len(X)):\n",
    "    LSTM_inputs[:, i] = X[i]\n",
    "LSTM_inputs = LSTM_inputs.T\n",
    "\n",
    "LSTM_outputs = np.zeros(shape=num_data_points)\n",
    "for i in range(len(labels)):\n",
    "    LSTM_outputs[i] = labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = LSTM_inputs[:train_size], LSTM_outputs[:train_size]\n",
    "x_test, y_test = LSTM_inputs[train_size:], LSTM_outputs[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size + 1, output_dim=64, input_length=max_length))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.2, batch_size=batch_size, epochs=num_epochs, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
